
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  HYDRACONTEXT CROSS-MODEL COMMUNICATION TEST
  Verifying standardization across different LLMs
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

======================================================================
TEST 1: Prompt Normalization Consistency
======================================================================

ğŸ“ Testing Prompt Normalization:

1. Messy whitespace
   Raw length: 41 chars
   Normalized length: 29 chars
   Detected type: instruction
   Token estimate: 7
   âœ… Normalized: Explain   quantum   computing

2. Instruction with format requirement
   Raw length: 49 chars
   Normalized length: 49 chars
   Detected type: instruction
   Token estimate: 12
   âœ… Normalized: What is 2+2? Answer in JSON format: {"result": X}

3. Mixed code and instruction
   Raw length: 61 chars
   Normalized length: 60 chars
   Detected type: code
   Token estimate: 15
   âœ… Normalized: ```python
def hello():
    print('hi')
```
Explain this code

4. Translation task
   Raw length: 40 chars
   Normalized length: 40 chars
   Detected type: instruction
   Token estimate: 10
   âœ… Normalized: Translate to French: Hello, how are you?


======================================================================
TEST 2: Multi-Format Response Parsing
======================================================================

ğŸ” Parsing Different Response Formats:

âœ… Ollama format
   Content: Quantum computing uses qubits instead of classical bits....
   Tokens: N/A
   Provider: ollama

âœ… OpenAI format
   Content: Quantum computing leverages quantum mechanics....
   Tokens: N/A
   Provider: openai

âœ… Anthropic format
   Content: [{'text': 'Quantum computing exploits superposition and enta...
   Tokens: N/A
   Provider: generic


======================================================================
TEST 3: Actual Cross-Model Communication
======================================================================

ğŸ”— Testing Information Chain:

Scenario: Each model builds on the previous model's output

Initial prompt: State one interesting fact about quantum computing in a single sentence.

Model                Task                           Status    
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
qwen2.5:0.5b         Generate fact                  âœ…
gemma:2b             Elaborate on fact              âœ…
llama3.2:3b          Add example                    âŒ Error
phi:latest           Summarize chain                âœ…

======================================================================
ğŸ“Š Information Transfer Results:
======================================================================

Step 1: qwen2.5:0.5b (Generate fact)
Output: Quantum computing is a revolutionary field that harnesses the principles of quantum mechanics to per...

Step 2: gemma:2b (Elaborate on fact)
Output: ## Elaborating on the potential of quantum computing:

**Key aspects of quantum computing:**

* **Qu...

Step 3: phi:latest (Summarize chain)
Output: Quantum computing leverages principles from quantum mechanics (such as superposition and entanglemen...

âœ… Cross-model communication successful!
   Information flowed through 3 different models
   Total information chain length: 3141 chars

======================================================================
TEST 4: Bidirectional Normalization Pipeline
======================================================================

ğŸ“¤ Testing bidirectional flow:

Original prompt: Explain the concept of neural networks in simple terms.

âœ… INPUT NORMALIZATION:
   Original: 55 chars
   Normalized: 55 chars
   Clean whitespace: âœ“

âœ… OUTPUT NORMALIZATION:
   1. qwen2.5:0.5b
      Output: Neural networks are a type of machine learning algorithm that is inspired by the...
      Length: 988 chars
   2. gemma:2b
      Output: Sure. Here's a simplified explanation of neural networks:

**What are Neural Net...
      Length: 2175 chars

âœ… CONSISTENCY CHECK:
   All outputs have 'content': True
   All outputs have 'metadata': True
   Standardized format: âœ…

âœ… NORMALIZATION STATISTICS:
   Inputs processed: 1
   Normalized successfully: âœ“

======================================================================
TEST 5: Semantic Preservation Test
======================================================================

ğŸ” Testing semantic preservation after normalization:

1. âœ… What    is    machine    learning?
   Normalized: What    is    machine    learning?
   Key terms preserved: True

2. âœ… Translate: Hello â†’ Bonjour
   Normalized: Translate: Hello â†’ Bonjour
   Key terms preserved: True

3. âœ… Calculate 2+2=?
   Normalized: Calculate 2+2=?
   Key terms preserved: True

Result: 3/3 tests passed

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  TEST SUMMARY
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

âœ… PASS     Prompt Normalization
âœ… PASS     Response Parsing
âœ… PASS     Cross-Model Communication
âœ… PASS     Bidirectional Normalization
âœ… PASS     Semantic Preservation

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: 5/5 tests passed

ğŸ‰ All tests passed! Cross-model communication is flawless.

âœ… VERIFIED:
   - Prompts are normalized consistently
   - Responses from different providers are parsed uniformly
   - Information flows seamlessly between models
   - Semantic meaning is preserved
   - Bidirectional normalization works correctly


========== FULL RESULTS ==========

   Normalized length: 60 chars
   Detected type: code
   Token estimate: 15
   âœ… Normalized: ```python
def hello():
    print('hi')
```
Explain this code

4. Translation task
   Raw length: 40 chars
   Normalized length: 40 chars
   Detected type: instruction
   Token estimate: 10
   âœ… Normalized: Translate to French: Hello, how are you?


======================================================================
TEST 2: Multi-Format Response Parsing
======================================================================

ğŸ” Parsing Different Response Formats:

âœ… Ollama format
   Content: Quantum computing uses qubits instead of classical bits....
   Tokens: N/A
   Provider: ollama

âœ… OpenAI format
   Content: Quantum computing leverages quantum mechanics....
   Tokens: N/A
   Provider: openai

âœ… Anthropic format
   Content: [{'text': 'Quantum computing exploits superposition and enta...
   Tokens: N/A
   Provider: generic


======================================================================
TEST 3: Actual Cross-Model Communication
======================================================================

ğŸ”— Testing Information Chain:

Scenario: Each model builds on the previous model's output

Initial prompt: State one interesting fact about quantum computing in a single sentence.

Model                Task                           Status    
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
qwen2.5:0.5b         Generate fact                  âœ…
gemma:2b             Elaborate on fact              âœ…
llama3.2:3b          Add example                    âŒ Error
phi:latest           Summarize chain                âœ…

======================================================================
ğŸ“Š Information Transfer Results:
======================================================================

Step 1: qwen2.5:0.5b (Generate fact)
Output: Quantum computing is a revolutionary field that harnesses the principles of quantum mechanics to per...

Step 2: gemma:2b (Elaborate on fact)
Output: ## Elaborating on the potential of quantum computing:

**Key aspects of quantum computing:**

* **Qu...

Step 3: phi:latest (Summarize chain)
Output: Quantum computing leverages principles from quantum mechanics (such as superposition and entanglemen...

âœ… Cross-model communication successful!
   Information flowed through 3 different models
   Total information chain length: 3141 chars

======================================================================
TEST 4: Bidirectional Normalization Pipeline
======================================================================

ğŸ“¤ Testing bidirectional flow:

Original prompt: Explain the concept of neural networks in simple terms.

âœ… INPUT NORMALIZATION:
   Original: 55 chars
   Normalized: 55 chars
   Clean whitespace: âœ“

âœ… OUTPUT NORMALIZATION:
   1. qwen2.5:0.5b
      Output: Neural networks are a type of machine learning algorithm that is inspired by the...
      Length: 988 chars
   2. gemma:2b
      Output: Sure. Here's a simplified explanation of neural networks:

**What are Neural Net...
      Length: 2175 chars

âœ… CONSISTENCY CHECK:
   All outputs have 'content': True
   All outputs have 'metadata': True
   Standardized format: âœ…

âœ… NORMALIZATION STATISTICS:
   Inputs processed: 1
   Normalized successfully: âœ“

======================================================================
TEST 5: Semantic Preservation Test
======================================================================

ğŸ” Testing semantic preservation after normalization:

1. âœ… What    is    machine    learning?
   Normalized: What    is    machine    learning?
   Key terms preserved: True

2. âœ… Translate: Hello â†’ Bonjour
   Normalized: Translate: Hello â†’ Bonjour
   Key terms preserved: True

3. âœ… Calculate 2+2=?
   Normalized: Calculate 2+2=?
   Key terms preserved: True

Result: 3/3 tests passed

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  TEST SUMMARY
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

âœ… PASS     Prompt Normalization
âœ… PASS     Response Parsing
âœ… PASS     Cross-Model Communication
âœ… PASS     Bidirectional Normalization
âœ… PASS     Semantic Preservation

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: 5/5 tests passed

ğŸ‰ All tests passed! Cross-model communication is flawless.

âœ… VERIFIED:
   - Prompts are normalized consistently
   - Responses from different providers are parsed uniformly
   - Information flows seamlessly between models
   - Semantic meaning is preserved
   - Bidirectional normalization works correctly
